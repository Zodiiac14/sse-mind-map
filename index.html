<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Mind Map</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="styles.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Mind Map</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#uvod-i-motivacija" id="toc-uvod-i-motivacija"><span
class="toc-section-number">1</span> Uvod i motivacija</a></li>
<li><a href="#nemv-nepomeren-estimator-minimalne-varijanse"
id="toc-nemv-nepomeren-estimator-minimalne-varijanse"><span
class="toc-section-number">2</span> NEMV – Nepomeren Estimator Minimalne
Varijanse</a></li>
<li><a href="#crdg-cramérrao-donja-granica"
id="toc-crdg-cramérrao-donja-granica"><span
class="toc-section-number">3</span> CRDG – Cramér–Rao Donja Granica</a>
<ul>
<li><a href="#fišerova-informacija" id="toc-fišerova-informacija"><span
class="toc-section-number">3.1</span> Fišerova informacija</a></li>
<li><a href="#uslov-regularnosti" id="toc-uslov-regularnosti"><span
class="toc-section-number">3.2</span> Uslov regularnosti</a></li>
<li><a href="#crdg-teorema" id="toc-crdg-teorema"><span
class="toc-section-number">3.3</span> CRDG – Teorema</a></li>
<li><a href="#signali-sn-theta-u-belom-gaussovom-šumu"
id="toc-signali-sn-theta-u-belom-gaussovom-šumu"><span
class="toc-section-number">3.4</span> Signali <span
class="math inline">s[n; \theta]</span> u belom Gaussovom šumu</a></li>
<li><a href="#crdg-za-funkciju-parametra"
id="toc-crdg-za-funkciju-parametra"><span
class="toc-section-number">3.5</span> CRDG za funkciju
parametra</a></li>
<li><a href="#konzistentnost-i-asimptotske-osobine"
id="toc-konzistentnost-i-asimptotske-osobine"><span
class="toc-section-number">3.6</span> Konzistentnost i asimptotske
osobine</a></li>
<li><a href="#fišerova-matrica-informacije"
id="toc-fišerova-matrica-informacije"><span
class="toc-section-number">3.7</span> Fišerova matrica
informacije</a></li>
<li><a href="#crdg-za-vektorski-parametar"
id="toc-crdg-za-vektorski-parametar"><span
class="toc-section-number">3.8</span> CRDG za vektorski
parametar</a></li>
</ul></li>
<li><a href="#linearni-gaussovski-modeli"
id="toc-linearni-gaussovski-modeli"><span
class="toc-section-number">4</span> Linearni Gaussovski Modeli</a>
<ul>
<li><a href="#efikasan-estimator-u-lg-modelu"
id="toc-efikasan-estimator-u-lg-modelu"><span
class="toc-section-number">4.1</span> Efikasan estimator u LG
modelu</a></li>
<li><a href="#primeri-primene-lg-modela"
id="toc-primeri-primene-lg-modela"><span
class="toc-section-number">4.2</span> Primeri primene LG modela</a></li>
<li><a href="#uslov-invertibilnosti"
id="toc-uslov-invertibilnosti"><span
class="toc-section-number">4.3</span> Uslov invertibilnosti</a></li>
<li><a href="#obojeni-šum" id="toc-obojeni-šum"><span
class="toc-section-number">4.4</span> Obojeni šum</a></li>
<li><a href="#posebni-slučajevi" id="toc-posebni-slučajevi"><span
class="toc-section-number">4.5</span> Posebni slučajevi</a></li>
</ul></li>
<li><a href="#nlne-najbolji-linearan-nepomeren-estimator-blue"
id="toc-nlne-najbolji-linearan-nepomeren-estimator-blue"><span
class="toc-section-number">5</span> NLNE – Najbolji linearan nepomeren
estimator (BLUE)</a>
<ul>
<li><a href="#motivacija" id="toc-motivacija"><span
class="toc-section-number">5.1</span> Motivacija</a></li>
<li><a href="#uslov-nepomerenosti-skalarni-slučaj"
id="toc-uslov-nepomerenosti-skalarni-slučaj"><span
class="toc-section-number">5.2</span> Uslov nepomerenosti (skalarni
slučaj)</a></li>
<li><a href="#nalaženje-nlne-skalarni-slučaj"
id="toc-nalaženje-nlne-skalarni-slučaj"><span
class="toc-section-number">5.3</span> Nalaženje NLNE (skalarni
slučaj)</a></li>
<li><a href="#kada-nlne-nije-adekvatan"
id="toc-kada-nlne-nije-adekvatan"><span
class="toc-section-number">5.4</span> Kada NLNE nije adekvatan?</a></li>
<li><a href="#vektorski-slučaj-blue-za-boldsymbolthetainmathbbrp"
id="toc-vektorski-slučaj-blue-za-boldsymbolthetainmathbbrp"><span
class="toc-section-number">5.5</span> Vektorski slučaj (BLUE za <span
class="math inline">\boldsymbol{\theta}\in\mathbb{R}^p</span>)</a></li>
<li><a href="#kratki-primeri-i-komentari"
id="toc-kratki-primeri-i-komentari"><span
class="toc-section-number">5.6</span> Kratki primeri i
komentari</a></li>
</ul></li>
<li><a href="#emv-mle-estimator-maksimalne-verodostojnosti"
id="toc-emv-mle-estimator-maksimalne-verodostojnosti"><span
class="toc-section-number">6</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</a></li>
<li><a href="#bayesovska-filozofija-i-emskg-posteriorna-sredina"
id="toc-bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="toc-section-number">7</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</a></li>
<li><a href="#opšta-bayesovska-estimacija-cena-i-rizik"
id="toc-opšta-bayesovska-estimacija-cena-i-rizik"><span
class="toc-section-number">8</span> Opšta Bayesovska estimacija: cena i
rizik</a></li>
<li><a href="#linearna-bayesovska-estimacija-lemskg-i-geometrija"
id="toc-linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="toc-section-number">9</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</a></li>
<li><a href="#kalmanov-filter-kf" id="toc-kalmanov-filter-kf"><span
class="toc-section-number">10</span> Kalmanov filter (KF)</a></li>
<li><a href="#povezanosti-redosled-učenja"
id="toc-povezanosti-redosled-učenja"><span
class="toc-section-number">11</span> Povezanosti (redosled
učenja)</a></li>
</ul>
</nav>
<h2 data-number="1" id="uvod-i-motivacija"><span
class="header-section-number">1</span> Uvod i motivacija</h2>
<details class="card">
<summary>
<strong>Šta je model u teoriji estimacije?</strong>
</summary>
<div class="card-body">
<p>Model u teoriji estimacije je f.g.v. za opservacije, pri čemu u <span
class="math inline">p</span> figuriše <span
class="math inline">\theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada kažemo da je estimator nepomeren?</strong>
</summary>
<div class="card-body">
<p>Kažemo da je estimator nepomeren kada u proseku daje tačnu vrednost
<span class="math inline">E[\hat{\theta}] = \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je pomeraj estimatora?</strong>
</summary>
<div class="card-body">
<p>Pomeraj estimatora ukazuje na sistematsku grešku: <span
class="math inline">b(\theta) = E(\hat{\theta}) - \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je srednja kvadratna greška estimatora?</strong>
</summary>
<div class="card-body">
<p><span class="math inline">\operatorname{mse}(\hat{\theta})=E\left[
(\hat{\theta} - \theta)^2
\right]=\operatorname{var}(\hat{\theta})+b^2(\theta)</span>. </p>
</div></details>
<hr />
<h2 data-number="2"
id="nemv-nepomeren-estimator-minimalne-varijanse"><span
class="header-section-number">2</span> NEMV – Nepomeren Estimator
Minimalne Varijanse</h2>
<details class="card">
<summary>
<strong>Da li je moguće odrediti EMSKG u frekventističkom
pristupu?</strong>
</summary>
<div class="card-body">
<p>Nije moguće odrediti estimator minimalne srednje kvadratne greške u
frekventističkom pristupu. Ako tražimo <strong>nepomeren</strong>
estimator, želimo onaj sa <strong>najmanjom varijansom</strong>.</p>
</div></details>
<ul>
<li><strong>Koraci:</strong>
<ol type="1">
<li>Definiši klasu nepomerenih estimatora (uslov <span
class="math inline">E\hat{\theta}=\theta</span>).</li>
<li>Nađi onaj sa minimalnom varijansom; kada postoji i kada ne
postoji.</li>
</ol></li>
<li><strong>Zašto:</strong> NEMV je „zlatni standard“ u klasi
nepomerenih estimatora; često služi kao referenca (donja granica).</li>
</ul>
<hr />
<h2 data-number="3" id="crdg-cramérrao-donja-granica"><span
class="header-section-number">3</span> CRDG – Cramér–Rao Donja
Granica</h2>
<details class="card">
<summary>
<strong>Šta je verodostojnost?</strong>
</summary>
<div class="card-body">
<p>Verodostojnost je funkcija gustine verovatnoće posmatrana kao
funkcija od <span class="math inline">\theta</span> za fiksno <span
class="math inline">x</span>:<br />
<span class="math inline">L(\theta) = p(x; \theta)</span>.<br />
Za razliku od FGV, ne mora biti normirana: <span
class="math inline">\int L(\theta) \, d\theta \neq 1</span> u opštem
slučaju.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda verodostojnost za <span class="math inline">x =
\theta w, \; w \sim \mathcal{N}(0, 1)</span>?</strong>
</summary>
<div class="card-body">
<p>Tada je <span class="math inline">x \sim \mathcal{N}(0,
\theta^2)</span> i:<br />
<span class="math inline">L(\theta) = \frac{1}{\sqrt{2\pi \theta^2}}
\exp\left( -\frac{x^2}{2\theta^2} \right)</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda verodostojnost za <span class="math inline">x \sim
U[0, \theta]</span>?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
L(\theta) =
\begin{cases}
\frac{1}{\theta}, &amp; \theta \geq x \\
0, &amp; \theta &lt; x
\end{cases}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Od čega zavisi tačnost estimatora u smislu
verodostojnosti?</strong>
</summary>
<div class="card-body">
<p>Od “zašiljenosti” funkcije verodostojnosti — uži i viši vrh znači
veću tačnost estimacije.</p>
</div></details>
<hr />
<h3 data-number="3.1" id="fišerova-informacija"><span
class="header-section-number">3.1</span> Fišerova informacija</h3>
<details class="card">
<summary>
<strong>Kako definišemo log-verodostojnost i Fišerovu
informaciju?</strong>
</summary>
<div class="card-body">
<p>Log-verodostojnost: <span class="math inline">\ell(\theta) = \ln p(x;
\theta)</span><br />
Fišerova informacija: <span class="math display">
I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(x;
\theta) \right]
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Koja je intuicija iza Fišerove informacije?</strong>
</summary>
<div class="card-body">
<p>Ona meri prosečnu zakrivljenost log-verodostojnosti — što je kriva
“oštrija”, to imamo više informacije o <span
class="math inline">\theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako se Fišerova informacija računa za nezavisne jednako
raspodeljene uzorke?</strong>
</summary>
<div class="card-body">
<p>Važi aditivnost:<br />
<span class="math inline">\ell(\theta) = \sum_{n=0}^{N-1} \ln p(x[n];
\theta)</span><br />
<span class="math inline">I(\theta) = \sum_{n=0}^{N-1}
I_n(\theta)</span></p>
</div></details>
<hr />
<h3 data-number="3.2" id="uslov-regularnosti"><span
class="header-section-number">3.2</span> Uslov regularnosti</h3>
<details class="card">
<summary>
<strong>Kako glasi uslov regularnosti CRDG?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
E\left[ \frac{\partial}{\partial \theta} \ln p(x; \theta) \right] = 0,
\quad \forall\theta
</span><br />
Ovaj izraz nazivamo Fišerov skor.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada važi ekvivalencija dve definicije Fišerove
informacije?</strong>
</summary>
<div class="card-body">
<p>Ako je ispunjen uslov regularnosti i izvod i integral mogu da zamene
mesta, tada: <span class="math display">
I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(x;
\theta) \right]
= E\left[ \left( \frac{\partial}{\partial \theta} \ln p(x; \theta)
\right)^2 \right]
</span></p>
</div></details>
<hr />
<h3 data-number="3.3" id="crdg-teorema"><span
class="header-section-number">3.3</span> CRDG – Teorema</h3>
<details class="card">
<summary>
<strong>Kako glasi Cramér–Rao donja granica za nepomereni
estimator?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\mathrm{var}(\hat{\theta}) \geq \frac{1}{I(\theta)}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kada postoji efikasan estimator koji dostiže CRDG?</strong>
</summary>
<div class="card-body">
<p>Ako postoji faktorizacija: <span class="math display">
\frac{\partial}{\partial \theta} \ln p(x; \theta) = i(\theta) \, [g(x) -
\theta]
</span> tada je <span class="math inline">\hat{\theta}_{\mathrm{NEMV}} =
g(x)</span> efikasan i: <span class="math display">
\mathrm{var}(\hat{\theta}_{\mathrm{NEMV}}) = \frac{1}{I(\theta)}
</span></p>
</div></details>
<hr />
<h3 data-number="3.4" id="signali-sn-theta-u-belom-gaussovom-šumu"><span
class="header-section-number">3.4</span> Signali <span
class="math inline">s[n; \theta]</span> u belom Gaussovom šumu</h3>
<details class="card">
<summary>
<strong>Kako izgleda model signala u belom Gaussovom šumu?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
x[n] = s[n; \theta] + w[n], \quad n = 0, 1, \dots, N-1
</span><br />
gde je <span class="math inline">w[n] \sim \mathcal{N}(0,
\sigma^2)</span> – beli Gaussov šum.</p>
</div></details>
<details class="card">
<summary>
<strong>Fišerova informacija za signale u belom Gaussovom šumu:</strong>
</summary>
<div class="card-body">
<p><span class="math display">
I(\theta) = \frac{1}{\sigma^2} \sum_{n=0}^{N-1} \left( \frac{\partial
s[n; \theta]}{\partial \theta} \right)^2
</span></p>
</div></details>
<hr />
<h3 data-number="3.5" id="crdg-za-funkciju-parametra"><span
class="header-section-number">3.5</span> CRDG za funkciju parametra</h3>
<details class="card">
<summary>
<strong>Kako glasi CRDG za <span class="math inline">\alpha =
a(\theta)</span>?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\mathrm{var}(\hat{\alpha}) \geq \frac{\left( \frac{da(\theta)}{d\theta}
\right)^2}{I(\theta)}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kada je efikasnost očuvana kod transformacije
estimatora?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">\hat{\theta}</span> efikasan
estimator za <span class="math inline">\theta</span>, onda je <span
class="math inline">\hat{\alpha} = a(\hat{\theta})</span> takođe
efikasan <strong>ako</strong> transformacija ima oblik:<br />
<span class="math display">
a(\theta) = c\,\theta + d
</span><br />
U tom slučaju: <span class="math display">
\mathrm{var}(\hat{\alpha}) = c^2\,\mathrm{var}(\hat{\theta}) =
\frac{c^2}{I(\theta)}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kada efikasnost nije očuvana?</strong>
</summary>
<div class="card-body">
<p>Ako <span class="math inline">a(\theta)</span> nije linearna funkcija
parametra, efikasnost u opštem slučaju <strong>nije</strong>
očuvana.<br />
Primer: <span class="math inline">A</span> u belom Gaussovom šumu —
<span class="math inline">\hat{A} = \bar{x}</span> efikasan, ali <span
class="math inline">\hat{\alpha} = \bar{x}^2</span> nije ni nepomeren ni
efikasan estimator za <span class="math inline">\alpha = A^2</span>.</p>
</div></details>
<hr />
<h3 data-number="3.6" id="konzistentnost-i-asimptotske-osobine"><span
class="header-section-number">3.6</span> Konzistentnost i asimptotske
osobine</h3>
<details class="card">
<summary>
<strong>Definicija konzistentnog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
konzistentan ako: <span class="math display">
\lim_{N \to \infty} \mathrm{var}(\hat{\theta}) = 0
</span> odnosno, <span class="math inline">\hat{\theta} \xrightarrow{P}
\theta</span> kada <span class="math inline">N</span> raste.</p>
</div></details>
<details class="card">
<summary>
<strong>Definicija asimptotski nepomerenog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
asimptotski nepomeren ako: <span class="math display">
\lim_{N \to \infty} E[\hat{\theta}] = \theta
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Definicija asimptotski efikasnog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
asimptotski efikasan ako: <span class="math display">
\lim_{N \to \infty} \mathrm{var}(\hat{\theta}) = \frac{1}{I(\theta)}
</span> odnosno, za veliko <span class="math inline">N</span> dostiže
CRDG.</p>
</div></details>
<hr />
<h3 data-number="3.7" id="fišerova-matrica-informacije"><span
class="header-section-number">3.7</span> Fišerova matrica
informacije</h3>
<details class="card">
<summary>
<strong>Šta je Fišerova matrica informacije?</strong>
</summary>
<div class="card-body">
<p>Fišerova matrica informacije je proširenje Fišerove informacije na
vektorski parametar <span class="math inline">\theta</span>.<br />
Definiše se kao: <span class="math display">
[I(\theta)]_{ij} = -E\left[ \frac{\partial^2}{\partial \theta_i \partial
\theta_j} \ln p(x; \theta) \right]
</span> ili ekvivalentno (pod uslovom regularnosti): <span
class="math display">
[I(\theta)]_{ij} = E\left[ \frac{\partial}{\partial \theta_i} \ln p(x;
\theta) \cdot \frac{\partial}{\partial \theta_j} \ln p(x; \theta)
\right]
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda Fišerova matrica u punom obliku?</strong>
</summary>
<div class="card-body">
<p>Za <span class="math inline">\theta = [\theta_1, \theta_2, \dots,
\theta_p]^T</span>: <span class="math display">
I(\theta) =
\begin{bmatrix}
-\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_1^2} \right] &amp;
-\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_2}
\right] &amp; \dots &amp; -\!E\!\left[ \frac{\partial^2 \ell}{\partial
\theta_1 \partial \theta_p} \right] \\
-\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_2 \partial \theta_1}
\right] &amp; -\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_2^2}
\right] &amp; \dots &amp; -\!E\!\left[ \frac{\partial^2 \ell}{\partial
\theta_2 \partial \theta_p} \right] \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_p \partial \theta_1}
\right] &amp; -\!E\!\left[ \frac{\partial^2 \ell}{\partial \theta_p
\partial \theta_2} \right] &amp; \dots &amp; -\!E\!\left[
\frac{\partial^2 \ell}{\partial \theta_p^2} \right]
\end{bmatrix}
</span> gde je <span class="math inline">\ell(\theta) = \ln p(x;
\theta)</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda Fišerova matrica za poznati model <span
class="math inline">x = A + w \sim \mathcal{N}(A, \sigma^2)</span> i
<span class="math inline">\theta = [A, \sigma^2]^T</span>?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\nabla_{\theta} \ln p(x; \theta) =
\begin{bmatrix}
\frac{x - \theta_1}{\theta_2} \\
-\frac{1}{2\theta_2} + \frac{(x - \theta_1)^2}{2\theta_2^2}
\end{bmatrix}
</span> Iz čega sledi: <span class="math display">
I(\theta) =
\begin{bmatrix}
\frac{1}{\theta_2} &amp; 0 \\
0 &amp; \frac{1}{2\theta_2^2}
\end{bmatrix}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Koji je uslov regularnosti za Fišerovu matricu?</strong>
</summary>
<div class="card-body">
<p>Za vektorski parametar <span class="math inline">\theta</span> uslov
regularnosti glasi: <span class="math display">
E\left[ \nabla_{\theta} \ln p(x; \theta) \right] = \mathbf{0}, \quad
\forall \theta
</span> odnosno: <span class="math display">
E\left[ \frac{\partial}{\partial \theta_i} \ln p(x; \theta) \right] = 0,
\quad \forall i
</span> Ovo znači da je očekivanje vektora Fišerovog skora jednako
nuli.</p>
</div></details>
<h3 data-number="3.8" id="crdg-za-vektorski-parametar"><span
class="header-section-number">3.8</span> CRDG za vektorski
parametar</h3>
<details class="card">
<summary>
<strong>Kako glasi Cramér–Rao Donja Granica za vektorski
parametar?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">\hat{\theta}</span> nepomeren
estimator vektora <span class="math inline">\theta</span> i ako je
ispunjen uslov regularnosti, tada: <span class="math display">
\mathbf{C}_{\hat{\theta}} - I^{-1}(\theta) \geq 0
</span> gde je <span
class="math inline">\mathbf{C}_{\hat{\theta}}</span> kovarijaciona
matrica estimatora, a <span class="math inline">I(\theta)</span>
Fišerova matrica informacije.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada je estimator efikasan u vektorskom slučaju?</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta} = g(x)</span> je
efikasan ako: <span class="math display">
\nabla_{\theta} \ln p(x; \theta) = I(\theta) \, [g(x) - \theta]
</span> i tada važi: <span class="math display">
\mathbf{C}_{\hat{\theta}} = I^{-1}(\theta)
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kako se CRDG transformiše kod promenljive <span
class="math inline">\alpha = a(\theta)</span>?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">\alpha = a(\theta)</span> i <span
class="math inline">J(a(\theta)) = \frac{\partial a(\theta)}{\partial
\theta}</span> Jakobijan transformacije, tada: <span
class="math display">
\mathbf{C}_{\hat{\alpha}} - J(a(\theta)) \, I^{-1}(\theta) \,
J^T(a(\theta)) \geq 0
</span></p>
</div></details>
<hr />
<h2 data-number="4" id="linearni-gaussovski-modeli"><span
class="header-section-number">4</span> Linearni Gaussovski Modeli</h2>
<details class="card">
<summary>
<strong>Šta je linearni Gaussovski model?</strong>
</summary>
<div class="card-body">
<p>Model oblika: <span class="math display">
x = H\theta + w
</span> gde je:</p>
<ul>
<li><p><span class="math inline">x</span> – vektor opservacija dimenzije
<span class="math inline">N \times 1</span></p></li>
<li><p><span class="math inline">\theta</span> – vektor nepoznatih
parametara dimenzije <span class="math inline">p \times
1</span></p></li>
<li><p><span class="math inline">w</span> – beli Gaussov šum, <span
class="math inline">w \sim \mathcal{N}(0, \sigma^2 I)</span></p></li>
<li><p><span class="math inline">H</span> – poznata opservaciona matrica
<span class="math inline">N \times p</span></p></li>
</ul>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda matrica opservacije za primer modelovanja cene
akcije:</strong> <span class="math display">
x[n] = \theta_0 + \theta_1 n + w[n], \quad n = 0, \dots, N-1
</span>
</summary>
<div class="card-body">
<p><span class="math display">
H =
\begin{bmatrix}
1 &amp; 0 \\
\vdots &amp; \vdots \\
1 &amp; N-1
\end{bmatrix}
</span></p>
</div></details>
<hr />
<h3 data-number="4.1" id="efikasan-estimator-u-lg-modelu"><span
class="header-section-number">4.1</span> Efikasan estimator u LG
modelu</h3>
<details class="card">
<summary>
<strong>Koji je efikasan estimator u LG modelu?</strong>
</summary>
<div class="card-body">
<p>Ako je rang(<span class="math inline">H^T H</span>) = <span
class="math inline">p</span>, efikasan estimator je: <span
class="math display">
\hat{\theta} = (H^T H)^{-1} H^T x
</span> sa kovarijacionom matricom: <span class="math display">
C_{\hat{\theta}} = \sigma^2 (H^T H)^{-1}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Koja su osnovna pravila diferenciranja kod vektora i
matrica?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">b</span> vektor i <span
class="math inline">A</span> simetrična matrica, važe: <span
class="math display">
\frac{\partial (b^T \theta)}{\partial \theta} = b, \quad
\frac{\partial (\theta^T A \theta)}{\partial \theta} = 2A\theta
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Šta znači uslov rang(<span class="math inline">H^T H</span>) =
p?</strong>
</summary>
<div class="card-body">
<p>To znači da je rang matrice <span class="math inline">H^T H</span>
jednak broju kolona matrice <span class="math inline">H</span>, tj. da
su kolone matrice <span class="math inline">H</span> linearno
nezavisne.<br />
Ovaj uslov je neophodan da bi <span class="math inline">(H^T
H)^{-1}</span> postojala.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je pseudo-inverzija matrice?</strong>
</summary>
<div class="card-body">
<p>Pseudo-inverzija (Moore–Penrose-ova inverzija) je generalizacija
inverza matrice koja postoji i kada matrica nije kvadratna ili nije
punog ranga.<br />
Ona omogućava rešavanje sistema najmanjih kvadrata kada <span
class="math inline">H</span> nije kvadratna, prema formuli: <span
class="math display">
H^+ = (H^T H)^{-1} H^T
</span> za slučaj kada <span class="math inline">H</span> ima pun rang
kolona.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda <span class="math inline">\hat{\theta}</span> kada
je <span class="math inline">H</span> kvadratna i invertibilna
matrica?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">H</span> kvadratna (<span
class="math inline">N = p</span>) i invertibilna, tada estimator ima
oblik: <span class="math display">
\hat{\theta} = H^{-1} x
</span> što je tačno rešenje sistema <span class="math inline">x =
H\theta</span> bez potrebe za metodom najmanjih kvadrata.</p>
</div></details>
<hr />
<h3 data-number="4.2" id="primeri-primene-lg-modela"><span
class="header-section-number">4.2</span> Primeri primene LG modela</h3>
<details class="card">
<summary>
<strong>U linearnoj regresiji imamo model:</strong> <span
class="math display">
x[n] = \theta_0 + n\theta_1 + w[n], \quad n = 0, \dots, N-1
</span> <strong>Kako izgleda matrica <span class="math inline">H</span>
u ovom slučaju?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
H =
\begin{bmatrix}
1 &amp; 0 \\
1 &amp; 1 \\
1 &amp; 2 \\
\vdots &amp; \vdots \\
1 &amp; N-1
\end{bmatrix}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>U polinomijalnoj regresiji reda <span
class="math inline">p</span> imamo model:</strong> <span
class="math display">
x[n] = \theta_0 + \theta_1 n + \dots + \theta_p n^p + w[n], \quad n = 0,
\dots, N-1
</span> <strong>Kako izgleda matrica <span class="math inline">H</span>
u ovom slučaju?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
H =
\begin{bmatrix}
1 &amp; 0 &amp; 0^2 &amp; \dots &amp; 0^p \\
1 &amp; 1 &amp; 1^2 &amp; \dots &amp; 1^p \\
1 &amp; 2 &amp; 2^2 &amp; \dots &amp; 2^p \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; N-1 &amp; (N-1)^2 &amp; \dots &amp; (N-1)^p
\end{bmatrix}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kod identifikacije impulsnog odziva LTI sistema imamo
model:</strong> <span class="math display">
x[n] = \sum_{k=0}^{p-1} \theta[k]\, u[n-k] + w[n], \quad n = 0, \dots,
N-1
</span> <strong>Kako izgleda matrica <span class="math inline">H</span>
u ovom slučaju?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
H =
\begin{bmatrix}
u[0] &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\
u[1] &amp; u[0] &amp; 0 &amp; \dots &amp; 0 \\
u[2] &amp; u[1] &amp; u[0] &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
u[N-1] &amp; u[N-2] &amp; u[N-3] &amp; \dots &amp; u[N-p]
\end{bmatrix}
</span></p>
</div></details>
<hr />
<h3 data-number="4.3" id="uslov-invertibilnosti"><span
class="header-section-number">4.3</span> Uslov invertibilnosti</h3>
<details class="card">
<summary>
<strong>Koji je uslov invertibilnosti za LG model?</strong>
</summary>
<div class="card-body">
<p>Matrica <span class="math inline">H</span> mora imati rang <span
class="math inline">p</span> — kolone <span class="math inline">H</span>
moraju biti linearno nezavisne.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta se dešava ako uslov invertibilnosti nije ispunjen?</strong>
</summary>
<div class="card-body">
<p>Ako kolone <span class="math inline">H</span> nisu linearno
nezavisne, rešenje po <span class="math inline">\theta</span> nije
jednoznačno čak i bez šuma.</p>
</div></details>
<hr />
<h3 data-number="4.4" id="obojeni-šum"><span
class="header-section-number">4.4</span> Obojeni šum</h3>
<details class="card">
<summary>
<strong>Šta je obojeni šum?</strong>
</summary>
<div class="card-body">
<p>Šum sa kovarijacionom matricom <span class="math inline">C \neq
\sigma^2 I</span>.<br />
<span class="math inline">w \sim \mathcal{N}(0, C)</span> sa <span
class="math inline">C &gt; 0</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako se LG model transformiše u beli šum kod obojenog
šuma?</strong>
</summary>
<div class="card-body">
<p>Ako <span class="math inline">C^{-1} = D^T D</span> (npr. iz Cholesky
dekompozicije), definišemo: <span class="math display">
x&#39; = D x, \quad H&#39; = D H, \quad w&#39; = D w
</span> Tada važi: <span class="math display">
\hat{\theta} = (H^T C^{-1} H)^{-1} H^T C^{-1} x
</span></p>
</div></details>
<hr />
<h3 data-number="4.5" id="posebni-slučajevi"><span
class="header-section-number">4.5</span> Posebni slučajevi</h3>
<details class="card">
<summary>
<strong>Kako se procenjuje konstanta u nestacionarnom nekorelisnom
Gaussovom šumu?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">x[n] = A + w[n]</span>, <span
class="math inline">w[n] \sim \mathcal{N}(0, \sigma_n^2)</span>, tada:
<span class="math display">
\hat{A} = \frac{\sum_{n=0}^{N-1}
\frac{x[n]}{\sigma_n^2}}{\sum_{n=0}^{N-1} \frac{1}{\sigma_n^2}}
</span> Merenja sa manjom varijansom dobijaju veći ponder.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako se procenjuje <span class="math inline">\theta</span> kad
signal ima poznatu komponentu <span
class="math inline">s</span>?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">x = H\theta + s + w</span>,<br />
oduzimamo poznatu komponentu: <span class="math display">
x&#39; = x - s
</span> i računamo: <span class="math display">
\hat{\theta} = (H^T H)^{-1} H^T (x - s)
</span></p>
</div></details>
<hr />
<h2 data-number="5"
id="nlne-najbolji-linearan-nepomeren-estimator-blue"><span
class="header-section-number">5</span> NLNE – Najbolji linearan
nepomeren estimator (BLUE)</h2>
<h3 data-number="5.1" id="motivacija"><span
class="header-section-number">5.1</span> Motivacija</h3>
<details class="card">
<summary>
<strong>Zašto uopšte uvodimo NLNE/BLUE?</strong>
</summary>
<div class="card-body">
<p>Kada <span class="math inline">p(x;\theta)</span> nije poznata ili
klasični kriterijumi (CRDG, rizično-bayesovski) nisu primenljivi,
ograničavamo se na <strong>linearne</strong> estimatore i tražimo onaj
koji je <strong>nepomeren</strong> i ima <strong>minimalnu
varijansu</strong>.<br />
Usvajamo linearni oblik: <span class="math display">
\hat{\theta} = \sum_{n=0}^{N-1} a_n\, x[n] = \mathbf{a}^T \mathbf{x}.
</span></p>
<p><strong>Intuicija:</strong> dovoljno su nam <span
class="math inline">E[\mathbf{x}]</span> i <span
class="math inline">\mathrm{cov}(\mathbf{x})</span>; ne moramo znati
celu raspodelu <span class="math inline">p(x;\theta)</span>.</p>
</div></details>
<hr />
<h3 data-number="5.2" id="uslov-nepomerenosti-skalarni-slučaj"><span
class="header-section-number">5.2</span> Uslov nepomerenosti (skalarni
slučaj)</h3>
<details class="card">
<summary>
<strong>Koji je uslov nepomerenosti za <span
class="math inline">\hat{\theta}=\mathbf{a}^T\mathbf{x}</span>?</strong>
</summary>
<div class="card-body">
<p>Ako je model očekivanja <span class="math inline">E[\mathbf{x}] =
\theta\,\mathbf{s}</span> sa poznatim <span
class="math inline">\mathbf{s}</span>, tada: <span class="math display">
E[\hat{\theta}] = \theta \;\;\Longleftrightarrow\;\; \mathbf{a}^T
\mathbf{s} = 1.
</span></p>
</div></details>
<hr />
<h3 data-number="5.3" id="nalaženje-nlne-skalarni-slučaj"><span
class="header-section-number">5.3</span> Nalaženje NLNE (skalarni
slučaj)</h3>
<details class="card">
<summary>
<strong>Kako naći NLNE kada znamo <span
class="math inline">\mathrm{cov}(\mathbf{x})=\mathbf{C}</span> i <span
class="math inline">E[\mathbf{x}]=\theta\mathbf{s}</span>?</strong>
</summary>
<div class="card-body">
<p>Minimizujemo varijansu uz uslov nepomerenosti: <span
class="math display">
\min_{\mathbf{a}}\;\mathbf{a}^T \mathbf{C}\,\mathbf{a}\quad
\text{uz}\quad \mathbf{a}^T \mathbf{s}=1.
</span> Lagrandžijan: <span class="math display">
L(\mathbf{a},\lambda) = \mathbf{a}^T\mathbf{C}\mathbf{a} +
\lambda\,(\mathbf{a}^T\mathbf{s}-1).
</span> Rešenje: <span class="math display">
\mathbf{a}_{\text{opt}} = \frac{\mathbf{C}^{-1}\mathbf{s}}{\mathbf{s}^T
\mathbf{C}^{-1}\mathbf{s}},\qquad
\mathrm{var}(\hat{\theta}) = \frac{1}{\mathbf{s}^T
\mathbf{C}^{-1}\mathbf{s}}.
</span></p>
<p><strong>Komentar (intuicija):</strong> ovo je “pretezani korelator” –
prvo <strong>izbeljivanje</strong> (<span
class="math inline">\mathbf{C}^{-1}</span>), pa
<strong>usklađivanje</strong> sa <span
class="math inline">\mathbf{s}</span>. U belom šumu <span
class="math inline">\mathbf{C}=\sigma^2\mathbf{I}</span> se svodi na
<span class="math display">
\mathbf{a}_{\text{opt}}=\frac{\mathbf{s}}{\mathbf{s}^T\mathbf{s}},\quad
\hat{\theta}=\frac{\mathbf{s}^T\mathbf{x}}{\mathbf{s}^T\mathbf{s}}.
</span></p>
</div></details>
<hr />
<h3 data-number="5.4" id="kada-nlne-nije-adekvatan"><span
class="header-section-number">5.4</span> Kada NLNE nije adekvatan?</h3>
<details class="card">
<summary>
<strong>Postoji li situacija u kojoj linearni nepomeren estimator ne
može da pomogne?</strong>
</summary>
<div class="card-body">
<p>Da. Ako je, recimo, <span class="math inline">E[x[n]]=0</span>, a
parametar je <span
class="math inline">\theta=\mathrm{var}\{x[n]\}</span>, svaki linearni
estimator <span class="math inline">\sum a_n x[n]</span> je
<strong>nepomeren za nulu</strong>, pa ne možemo linearnim putem doći do
<span class="math inline">\theta</span>.<br />
<strong>Intuicija:</strong> kada je informacija o parametru
“kvadratična”, treba nelinearan pristup (npr. koristiti <span
class="math inline">x^2[n]</span>).</p>
</div></details>
<hr />
<h3 data-number="5.5"
id="vektorski-slučaj-blue-za-boldsymbolthetainmathbbrp"><span
class="header-section-number">5.5</span> Vektorski slučaj (BLUE za <span
class="math inline">\boldsymbol{\theta}\in\mathbb{R}^p</span>)</h3>
<details class="card">
<summary>
<strong>Kako izgleda linearni nepomeren estimator vektora?</strong>
</summary>
<div class="card-body">
<p>Uzimamo <span
class="math inline">\hat{\boldsymbol{\theta}}=\mathbf{A}\mathbf{x}</span>
i tražimo nepomerenost uz model <span
class="math inline">E[\mathbf{x}]=\mathbf{H}\boldsymbol{\theta}</span>:
<span class="math display">
E[\hat{\boldsymbol{\theta}}]=\boldsymbol{\theta}
\;\;\Longleftrightarrow\;\;
\mathbf{A}\mathbf{H}=\mathbf{I}.
</span> Komponentno: neka su <span
class="math inline">\mathbf{a}_i^T</span> vrste od <span
class="math inline">\mathbf{A}</span> i <span
class="math inline">\mathbf{h}_j</span> kolone od <span
class="math inline">\mathbf{H}</span>. Tada: <span class="math display">
\mathbf{a}_i^T\mathbf{h}_j = \delta_{ij}.
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kako naći <span class="math inline">\mathbf{A}</span> sa
minimalnom kovarijansom?</strong>
</summary>
<div class="card-body">
<p>Minimizujemo svaku <span
class="math inline">\mathrm{var}(\hat{\theta}_i)=[\mathbf{A}\mathbf{C}\mathbf{A}^T]_{ii}</span>
pod ograničenjem <span
class="math inline">\mathbf{A}\mathbf{H}=\mathbf{I}</span>.<br />
Rezultat (BLUE/GLS): <span class="math display">
\boxed{\;
\hat{\boldsymbol{\theta}} =
(\mathbf{H}^T\mathbf{C}^{-1}\mathbf{H})^{-1}\mathbf{H}^T\mathbf{C}^{-1}\mathbf{x},\qquad
\mathbf{C}_{\hat{\boldsymbol{\theta}}} =
(\mathbf{H}^T\mathbf{C}^{-1}\mathbf{H})^{-1}
\;}
</span></p>
<p>Za <span class="math inline">\mathbf{C}=\sigma^2\mathbf{I}</span>
dobijamo klasični LGM: <span class="math display">
\hat{\boldsymbol{\theta}}=(\mathbf{H}^T\mathbf{H})^{-1}\mathbf{H}^T\mathbf{x}.
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kakva je veza sa NEMV (MVUE) u linearnom Gaussovom
modelu?</strong>
</summary>
<div class="card-body">
<p>Ako je <span
class="math inline">\mathbf{x}=\mathbf{H}\boldsymbol{\theta}+\mathbf{w}</span>
sa <span
class="math inline">\mathbf{w}\sim\mathcal{N}(\mathbf{0},\mathbf{C})</span>,
tada je BLUE iznad <strong>istovremeno i MVUE</strong>: <span
class="math display">
\text{NLNE} \equiv \text{NEMV} \quad (\text{u linearnom Gaussovom
modelu}).
</span></p>
<p><strong>Intuicija:</strong> Gaussov slučaj “zatvara krug”: linearni,
nepomeren i minimalne varijanse je ujedno i globalno optimalan među svim
nepomerenim.</p>
</div></details>
<hr />
<h3 data-number="5.6" id="kratki-primeri-i-komentari"><span
class="header-section-number">5.6</span> Kratki primeri i komentari</h3>
<details class="card">
<summary>
<strong>Primer (skalar, beli šum):</strong><br />
Model <span class="math inline">E[\mathbf{x}]=\theta\,\mathbf{s}</span>,
<span class="math inline">\mathbf{C}=\sigma^2\mathbf{I}</span>.<br />
<strong>Rešenje:</strong> <span
class="math inline">\;\hat{\theta}=\dfrac{\mathbf{s}^T\mathbf{x}}{\mathbf{s}^T\mathbf{s}},\;\;
\mathrm{var}(\hat{\theta})=\dfrac{\sigma^2}{\mathbf{s}^T\mathbf{s}}.</span>
</summary>
<div class="card-body">
<p><strong>Komentar:</strong> poredi “oblik” <span
class="math inline">\mathbf{x}</span> sa šablonom <span
class="math inline">\mathbf{s}</span>; što je energija šablona veća,
preciznost je veća.</p>
</div></details>
<details class="card">
<summary>
<strong>Primer (vektor, obojeni šum):</strong><br />
<span
class="math inline">\mathbf{x}=\mathbf{H}\boldsymbol{\theta}+\mathbf{w}</span>,
<span
class="math inline">\mathrm{cov}(\mathbf{x})=\mathbf{C}</span>.<br />
<strong>Rešenje (GLS/BLUE):</strong> <span class="math display">
\hat{\boldsymbol{\theta}}=(\mathbf{H}^T\mathbf{C}^{-1}\mathbf{H})^{-1}\mathbf{H}^T\mathbf{C}^{-1}\mathbf{x}.
</span>
</summary>
<div class="card-body">
<p><strong>Komentar:</strong> “izbeljivanjem” sa <span
class="math inline">\mathbf{C}^{-1}</span> svodimo problem na OLS nad
pretežiranim uzorcima; merenja sa velikom varijansom manje utiču.</p>
</div></details>
<hr />
<h2 data-number="6"
id="emv-mle-estimator-maksimalne-verodostojnosti"><span
class="header-section-number">6</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</h2>
<ul>
<li><strong>Poenta:</strong> Maksimizuje <span
class="math inline">L(\theta)=p(x;\theta)</span> (ili <span
class="math inline">\ell=\ln L</span>).</li>
<li><strong>Osobine:</strong> asimptotski <strong>nepomeren, normalan,
efikasan</strong> (za <span class="math inline">N\to\infty</span>).</li>
<li><strong>Zašto:</strong> univerzalan i često praktičan kada
NEMV/RBLST ne rade; daje iste rezultate kao OLS u Gaussovom
slučaju.</li>
<li><strong>Primer:</strong> Bernoulli <span
class="math inline">p</span>: <span class="math inline">\hat
p=\frac{1}{N}\sum x[n]</span>; konstanta u WGN: <span
class="math inline">\hat A=\bar x</span>.</li>
</ul>
<hr />
<h2 data-number="7"
id="bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="header-section-number">7</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</h2>
<ul>
<li><strong>Poenta:</strong> Parametar <span
class="math inline">\theta</span> je slučajan; koristimo apriorno <span
class="math inline">p(\theta)</span> i dobijamo aposteriorno <span
class="math inline">p(\theta\mid x)\propto
p(x\mid\theta)p(\theta)</span>.</li>
<li><strong>Optimalno za kvadratnu cenu:</strong> <span
class="math inline">\hat\theta=E(\theta\mid x)</span> = EMSKG.</li>
<li><strong>Gauss–Gauss slučaj:</strong> zatvorena forma za <span
class="math inline">\mu_{\theta\mid x}</span> i <span
class="math inline">C_{\theta\mid x}</span>; „data–prior“ fuzija.</li>
<li><strong>Zašto:</strong> ugradnja predznanja; često manja BSKG od
NEMV u proseku.</li>
<li><strong>Primer:</strong> konstanta sa uniformnim ili normalnim
priorom ⇒ shrinkage ka <span class="math inline">\mu_A</span>.</li>
</ul>
<hr />
<h2 data-number="8" id="opšta-bayesovska-estimacija-cena-i-rizik"><span
class="header-section-number">8</span> Opšta Bayesovska estimacija: cena
i rizik</h2>
<ul>
<li><strong>Poenta:</strong> Definišeš <strong>cenu</strong> <span
class="math inline">C(\epsilon)</span> i minimizuješ
<strong>rizik</strong> <span
class="math inline">R=E\,C(\theta-\hat\theta)</span>.</li>
<li><strong>Rezultati:</strong>
<ul>
<li>Kvadratna cena ⇒ <strong>posteriorna sredina</strong>.</li>
<li>Apsolutna cena ⇒ <strong>posteriorna medijana</strong>.</li>
<li>0/1 cena (δ→0) ⇒ <strong>MAP</strong> (posteriorni maksimum).</li>
</ul></li>
<li><strong>Zašto:</strong> omogućava izbor estimatora po zahtevu
aplikacije (robustnost, tolerancija, greške tipa „preko praga“).</li>
<li><strong>Primer:</strong> MAP sa uniformnim ograničenim priorom ⇒
„odsečena“ Gaussova posteriorna.</li>
</ul>
<hr />
<h2 data-number="9"
id="linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="header-section-number">9</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</h2>
<ul>
<li><strong>LEMSKG:</strong> <span
class="math inline">\hat\theta=E\theta + C_{\theta x} C_x^{-1}(x-E
x)</span>. </li>
<li><strong>Geometrija:</strong> projekcija <span
class="math inline">\theta</span> na potprostor koji „nose” <span
class="math inline">x</span>-ovi; <strong>princip
ortogonalnosti</strong>.</li>
<li><strong>Sekvencijalna forma (inovacije):</strong> rekurzivno
ažuriranje preko <span class="math inline">k[n]</span> i kovarijanse
greške <span class="math inline">M[n]</span>.</li>
<li><strong>Zašto:</strong> isti oblik kao Gauss–Bayes; priprema teren
za Kalmanov filter.</li>
<li><strong>Primer:</strong> dodavanje nove merenja kao „projekcije“ na
komponentu inovacije.</li>
</ul>
<hr />
<h2 data-number="10" id="kalmanov-filter-kf"><span
class="header-section-number">10</span> Kalmanov filter (KF)</h2>
<ul>
<li><strong>Model:</strong> Gauss–Markov stanje + BGŠ merenja.</li>
<li><strong>Rekurzije (skalar):</strong>
<ul>
<li>Predikcija: <span class="math inline">\hat s_{n|n-1}=a\,\hat
s_{n-1|n-1}</span>, <span class="math inline">M_{n|n-1}=a^2
M_{n-1|n-1}+\sigma_u^2</span>.</li>
<li>Pojačanje: <span class="math inline">K_n=
M_{n|n-1}/(\sigma_w^2+M_{n|n-1})</span>.</li>
<li>Ažuriranje: <span class="math inline">\hat s_{n|n}=\hat
s_{n|n-1}+K_n\,(x_n-\hat s_{n|n-1})</span>, <span
class="math inline">M_{n|n}=(1-K_n)M_{n|n-1}</span>.</li>
</ul></li>
<li><strong>Zašto:</strong> optimalna sekvencijalna fuzija informacija
(EMSKG=LEMSKG u Gaussovom slučaju); osnov za praćenje, navigaciju,
komunikacije.</li>
<li><strong>Primer:</strong> praćenje sporog signala u šumu; glatkoća vs
odziv zavisi od <span
class="math inline">\sigma_u^2,\sigma_w^2</span>.</li>
</ul>
<hr />
<h2 data-number="11" id="povezanosti-redosled-učenja"><span
class="header-section-number">11</span> Povezanosti (redosled
učenja)</h2>
<ol type="1">
<li><strong>Uvod → SKG/bias–var</strong> (razumevanje metrike)</li>
<li><strong>NEMV → CRLB</strong> (granice, efikasnost)</li>
<li><strong>LGM</strong> (matrični oblik; uslovi; obojeni šum)</li>
<li><strong>NLNE/BLUE</strong> (kada pdf nije poznat → oblik kao u
LGM)</li>
<li><strong>MLE</strong> (opšti metod; asimptotika)</li>
<li><strong>Bayes (EMSKG) → OBE</strong> (posterior, cena/rizik)</li>
<li><strong>LEMSKG</strong> (projekcija, inovacije)</li>
<li><strong>Kalman</strong> (sekvencijalni EMSKG/LEMSKG u GMM)
<a href="#top" class="back-to-top">⇧</a></li>
</ol>
<!-- cache-bust 20250813153309 --></body>
</html>
