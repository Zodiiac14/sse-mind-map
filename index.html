<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Mind Map</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="styles.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Mind Map</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#uvod-i-motivacija" id="toc-uvod-i-motivacija"><span
class="toc-section-number">1</span> Uvod i motivacija</a></li>
<li><a href="#nemv-nepomeren-estimator-minimalne-varijanse"
id="toc-nemv-nepomeren-estimator-minimalne-varijanse"><span
class="toc-section-number">2</span> NEMV – Nepomeren Estimator Minimalne
Varijanse</a></li>
<li><a href="#crdg-cramérrao-donja-granica"
id="toc-crdg-cramérrao-donja-granica"><span
class="toc-section-number">3</span> CRDG – Cramér–Rao Donja
Granica</a></li>
<li><a href="#fišerova-informacija" id="toc-fišerova-informacija"><span
class="toc-section-number">4</span> Fišerova informacija</a></li>
<li><a href="#uslov-regularnosti" id="toc-uslov-regularnosti"><span
class="toc-section-number">5</span> Uslov regularnosti</a></li>
<li><a href="#crdg-teorema" id="toc-crdg-teorema"><span
class="toc-section-number">6</span> CRDG – Teorema</a></li>
<li><a href="#crdg-za-funkciju-parametra"
id="toc-crdg-za-funkciju-parametra"><span
class="toc-section-number">7</span> CRDG za funkciju parametra</a></li>
<li><a href="#očuvanje-efikasnosti-estimatora"
id="toc-očuvanje-efikasnosti-estimatora"><span
class="toc-section-number">8</span> Očuvanje efikasnosti
estimatora</a></li>
<li><a href="#konzistentnost-i-asimptotske-osobine"
id="toc-konzistentnost-i-asimptotske-osobine"><span
class="toc-section-number">9</span> Konzistentnost i asimptotske
osobine</a></li>
<li><a href="#signali-sn-theta-u-belom-gaussovom-šumu"
id="toc-signali-sn-theta-u-belom-gaussovom-šumu"><span
class="toc-section-number">10</span> Signali <span
class="math inline">s[n; \theta]</span> u belom Gaussovom šumu</a></li>
<li><a href="#lgm-linearni-gaussovski-model-ols"
id="toc-lgm-linearni-gaussovski-model-ols"><span
class="toc-section-number">11</span> LGM – Linearni Gaussovski Model
(OLS)</a></li>
<li><a href="#nlne-blue-najbolji-linearan-nepomeren-estimator"
id="toc-nlne-blue-najbolji-linearan-nepomeren-estimator"><span
class="toc-section-number">12</span> NLNE / BLUE – Najbolji Linearan
Nepomeren Estimator</a></li>
<li><a href="#emv-mle-estimator-maksimalne-verodostojnosti"
id="toc-emv-mle-estimator-maksimalne-verodostojnosti"><span
class="toc-section-number">13</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</a></li>
<li><a href="#bayesovska-filozofija-i-emskg-posteriorna-sredina"
id="toc-bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="toc-section-number">14</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</a></li>
<li><a href="#opšta-bayesovska-estimacija-cena-i-rizik"
id="toc-opšta-bayesovska-estimacija-cena-i-rizik"><span
class="toc-section-number">15</span> Opšta Bayesovska estimacija: cena i
rizik</a></li>
<li><a href="#linearna-bayesovska-estimacija-lemskg-i-geometrija"
id="toc-linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="toc-section-number">16</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</a></li>
<li><a href="#kalmanov-filter-kf" id="toc-kalmanov-filter-kf"><span
class="toc-section-number">17</span> Kalmanov filter (KF)</a></li>
<li><a href="#povezanosti-redosled-učenja"
id="toc-povezanosti-redosled-učenja"><span
class="toc-section-number">18</span> Povezanosti (redosled
učenja)</a></li>
</ul>
</nav>
<h2 data-number="1" id="uvod-i-motivacija"><span
class="header-section-number">1</span> Uvod i motivacija</h2>
<details class="card">
<summary>
<strong>Šta je model u teoriji estimacije?</strong>
</summary>
<div class="card-body">
<p>Model u teoriji estimacije je f.g.v. za opservacije, pri čemu u <span
class="math inline">p</span> figuriše <span
class="math inline">\theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada kažemo da je estimator nepomeren?</strong>
</summary>
<div class="card-body">
<p>Kažemo da je estimator nepomeren kada u proseku daje tačnu vrednost
<span class="math inline">E[\hat{\theta}] = \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je pomeraj estimatora?</strong>
</summary>
<div class="card-body">
<p>Pomeraj estimatora ukazuje na sistematsku grešku: <span
class="math inline">b(\theta) = E(\hat{\theta}) - \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je srednja kvadratna greška estimatora?</strong>
</summary>
<div class="card-body">
<p><span class="math inline">\operatorname{mse}(\hat{\theta})=E\left[
(\hat{\theta} - \theta)^2
\right]=\operatorname{var}(\hat{\theta})+b^2(\theta)</span>. </p>
</div></details>
<hr />
<h2 data-number="2"
id="nemv-nepomeren-estimator-minimalne-varijanse"><span
class="header-section-number">2</span> NEMV – Nepomeren Estimator
Minimalne Varijanse</h2>
<details class="card">
<summary>
<strong>Da li je moguće odrediti EMSKG u frekventističkom
pristupu?</strong>
</summary>
<div class="card-body">
<p>Nije moguće odrediti estimator minimalne srednje kvadratne greške u
frekventističkom pristupu. Ako tražimo <strong>nepomeren</strong>
estimator, želimo onaj sa <strong>najmanjom varijansom</strong>.</p>
</div></details>
<ul>
<li><strong>Koraci:</strong>
<ol type="1">
<li>Definiši klasu nepomerenih estimatora (uslov <span
class="math inline">E\hat{\theta}=\theta</span>).</li>
<li>Nađi onaj sa minimalnom varijansom; kada postoji i kada ne
postoji.</li>
</ol></li>
<li><strong>Zašto:</strong> NEMV je „zlatni standard“ u klasi
nepomerenih estimatora; često služi kao referenca (donja granica).</li>
</ul>
<hr />
<h2 data-number="3" id="crdg-cramérrao-donja-granica"><span
class="header-section-number">3</span> CRDG – Cramér–Rao Donja
Granica</h2>
<details class="card">
<summary>
<strong>Šta je verodostojnost?</strong>
</summary>
<div class="card-body">
<p>Verodostojnost je funkcija gustine verovatnoće posmatrana kao
funkcija od <span class="math inline">\theta</span> za fiksno <span
class="math inline">x</span>:<br />
<span class="math inline">L(\theta) = p(x; \theta)</span>.<br />
Za razliku od FGV, ne mora biti normirana: <span
class="math inline">\int L(\theta) \, d\theta \neq 1</span> u opštem
slučaju.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda verodostojnost za <span class="math inline">x =
\theta w, \; w \sim \mathcal{N}(0, 1)</span>?</strong>
</summary>
<div class="card-body">
<p>Tada je <span class="math inline">x \sim \mathcal{N}(0,
\theta^2)</span> i:<br />
<span class="math inline">L(\theta) = \frac{1}{\sqrt{2\pi \theta^2}}
\exp\left( -\frac{x^2}{2\theta^2} \right)</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda verodostojnost za <span class="math inline">x \sim
U[0, \theta]</span>?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
L(\theta) =
\begin{cases}
\frac{1}{\theta}, &amp; \theta \geq x \\
0, &amp; \theta &lt; x
\end{cases}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Od čega zavisi tačnost estimatora u smislu
verodostojnosti?</strong>
</summary>
<div class="card-body">
<p>Od “zašiljenosti” funkcije verodostojnosti — uži i viši vrh znači
veću tačnost estimacije.</p>
</div></details>
<hr />
<h2 data-number="4" id="fišerova-informacija"><span
class="header-section-number">4</span> Fišerova informacija</h2>
<details class="card">
<summary>
<strong>Kako definišemo log-verodostojnost i Fišerovu
informaciju?</strong>
</summary>
<div class="card-body">
<p>Log-verodostojnost: <span class="math inline">\ell(\theta) = \ln p(x;
\theta)</span><br />
Fišerova informacija: <span class="math display">
I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(x;
\theta) \right]
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Koja je intuicija iza Fišerove informacije?</strong>
</summary>
<div class="card-body">
<p>Ona meri prosečnu zakrivljenost log-verodostojnosti — što je kriva
“oštrija”, to imamo više informacije o <span
class="math inline">\theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako se Fišerova informacija računa za nezavisne jednako
raspodeljene uzorke?</strong>
</summary>
<div class="card-body">
<p>Važi aditivnost:<br />
<span class="math inline">\ell(\theta) = \sum_{n=0}^{N-1} \ln p(x[n];
\theta)</span><br />
<span class="math inline">I(\theta) = \sum_{n=0}^{N-1}
I_n(\theta)</span></p>
</div></details>
<hr />
<h2 data-number="5" id="uslov-regularnosti"><span
class="header-section-number">5</span> Uslov regularnosti</h2>
<details class="card">
<summary>
<strong>Kako glasi uslov regularnosti CRDG?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
E\left[ \frac{\partial}{\partial \theta} \ln p(x; \theta) \right] = 0,
\quad \forall\theta
</span><br />
Ovaj izraz nazivamo Fišerov skor.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada važi ekvivalencija dve definicije Fišerove
informacije?</strong>
</summary>
<div class="card-body">
<p>Ako je ispunjen uslov regularnosti, tada: <span class="math display">
I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(x;
\theta) \right]
= E\left[ \left( \frac{\partial}{\partial \theta} \ln p(x; \theta)
\right)^2 \right]
</span></p>
</div></details>
<hr />
<h2 data-number="6" id="crdg-teorema"><span
class="header-section-number">6</span> CRDG – Teorema</h2>
<details class="card">
<summary>
<strong>Kako glasi Cramér–Rao donja granica za nepomereni
estimator?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\mathrm{var}(\hat{\theta}) \geq \frac{1}{I(\theta)}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kada postoji efikasan estimator koji dostiže CRDG?</strong>
</summary>
<div class="card-body">
<p>Ako postoji faktorizacija: <span class="math display">
\frac{\partial}{\partial \theta} \ln p(x; \theta) = i(\theta) \, [g(x) -
\theta]
</span> tada je <span class="math inline">\hat{\theta}_{\mathrm{NEMV}} =
g(x)</span> efikasan i: <span class="math display">
\mathrm{var}(\hat{\theta}_{\mathrm{NEMV}}) = \frac{1}{I(\theta)}
</span></p>
</div></details>
<hr />
<h2 data-number="7" id="crdg-za-funkciju-parametra"><span
class="header-section-number">7</span> CRDG za funkciju parametra</h2>
<details class="card">
<summary>
<strong>Kako glasi CRDG za <span class="math inline">\alpha =
a(\theta)</span>?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\mathrm{var}(\hat{\alpha}) \geq \frac{\left( \frac{da(\theta)}{d\theta}
\right)^2}{I(\theta)}
</span></p>
</div></details>
<hr />
<h2 data-number="8" id="očuvanje-efikasnosti-estimatora"><span
class="header-section-number">8</span> Očuvanje efikasnosti
estimatora</h2>
<details class="card">
<summary>
<strong>Kada je efikasnost očuvana kod transformacije
estimatora?</strong>
</summary>
<div class="card-body">
<p>Ako je <span class="math inline">\hat{\theta}</span> efikasan
estimator za <span class="math inline">\theta</span>, onda je <span
class="math inline">\hat{\alpha} = a(\hat{\theta})</span> takođe
efikasan <strong>ako</strong> transformacija ima oblik:<br />
<span class="math display">
a(\theta) = c\,\theta + d
</span><br />
U tom slučaju: <span class="math display">
\mathrm{var}(\hat{\alpha}) = c^2\,\mathrm{var}(\hat{\theta}) =
\frac{c^2}{I(\theta)}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Kada efikasnost nije očuvana?</strong>
</summary>
<div class="card-body">
<p>Ako <span class="math inline">a(\theta)</span> nije linearna funkcija
parametra, efikasnost u opštem slučaju <strong>nije</strong>
očuvana.<br />
Primer: <span class="math inline">A</span> u belom Gaussovom šumu —
<span class="math inline">\hat{A} = \bar{x}</span> efikasan, ali <span
class="math inline">\hat{\alpha} = \bar{x}^2</span> nije ni nepomeren ni
efikasan estimator za <span class="math inline">\alpha = A^2</span>.</p>
</div></details>
<hr />
<h2 data-number="9" id="konzistentnost-i-asimptotske-osobine"><span
class="header-section-number">9</span> Konzistentnost i asimptotske
osobine</h2>
<details class="card">
<summary>
<strong>Definicija konzistentnog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
konzistentan ako: <span class="math display">
\lim_{N \to \infty} \mathrm{var}(\hat{\theta}) = 0
</span> odnosno, <span class="math inline">\hat{\theta} \xrightarrow{P}
\theta</span> kada <span class="math inline">N</span> raste.</p>
</div></details>
<details class="card">
<summary>
<strong>Definicija asimptotski nepomerenog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
asimptotski nepomeren ako: <span class="math display">
\lim_{N \to \infty} E[\hat{\theta}] = \theta
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Definicija asimptotski efikasnog estimatora</strong>
</summary>
<div class="card-body">
<p>Estimator <span class="math inline">\hat{\theta}</span> je
asimptotski efikasan ako: <span class="math display">
\lim_{N \to \infty} \mathrm{var}(\hat{\theta}) = \frac{1}{I(\theta)}
</span> odnosno, za veliko <span class="math inline">N</span> dostiže
CRDG.</p>
</div></details>
<hr />
<h2 data-number="10" id="signali-sn-theta-u-belom-gaussovom-šumu"><span
class="header-section-number">10</span> Signali <span
class="math inline">s[n; \theta]</span> u belom Gaussovom šumu</h2>
<details class="card">
<summary>
<strong>Kako izgleda model signala u belom Gaussovom šumu?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
x[n] = s[n; \theta] + w[n], \quad n = 0, 1, \dots, N-1
</span><br />
gde je <span class="math inline">w[n] \sim \mathcal{N}(0,
\sigma^2)</span> – beli Gaussov šum.</p>
</div></details>
<details class="card">
<summary>
<strong>Kako izgleda log-verodostojnost za ovaj model?</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\ln p(x; \theta) = -\frac{N}{2} \ln(2\pi\sigma^2) - \frac{1}{2\sigma^2}
\sum_{n=0}^{N-1} (x[n] - s[n; \theta])^2
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Prvi izvod log-verodostojnosti po <span
class="math inline">\theta</span>:</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\frac{\partial}{\partial \theta} \ln p(x; \theta) = \frac{1}{\sigma^2}
\sum_{n=0}^{N-1} (x[n] - s[n; \theta]) \frac{\partial s[n;
\theta]}{\partial \theta}
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Drugi izvod log-verodostojnosti po <span
class="math inline">\theta</span>:</strong>
</summary>
<div class="card-body">
<p><span class="math display">
\frac{\partial^2}{\partial \theta^2} \ln p(x; \theta) =
\frac{1}{\sigma^2} \sum_{n=0}^{N-1} \left[ (x[n] - s[n; \theta])
\frac{\partial^2 s[n; \theta]}{\partial \theta^2} - \left(
\frac{\partial s[n; \theta]}{\partial \theta} \right)^2 \right]
</span></p>
</div></details>
<details class="card">
<summary>
<strong>Fišerova informacija za signale u belom Gaussovom šumu:</strong>
</summary>
<div class="card-body">
<p><span class="math display">
I(\theta) = \frac{1}{\sigma^2} \sum_{n=0}^{N-1} \left( \frac{\partial
s[n; \theta]}{\partial \theta} \right)^2
</span></p>
</div></details>
<hr />
<h2 data-number="11" id="lgm-linearni-gaussovski-model-ols"><span
class="header-section-number">11</span> LGM – Linearni Gaussovski Model
(OLS)</h2>
<ul>
<li><strong>Model:</strong> <span
class="math inline">x=H\,\theta+w</span>, <span
class="math inline">w\sim\mathcal N(0,\sigma^2 I)</span>.</li>
<li><strong>Efikasni estimator (i NEMV):</strong> <span
class="math inline">\hat{\theta}=(H^T H)^{-1}H^T x</span>. </li>
<li><strong>Varijansa:</strong> <span
class="math inline">C_{\hat{\theta}}=\sigma^2 (H^T H)^{-1}</span>.</li>
<li><strong>Obojeni šum:</strong> prewhitening sa <span
class="math inline">C^{-1}=D^T D</span> ⇒ <span
class="math inline">\hat\theta=(H^T C^{-1} H)^{-1}H^T
C^{-1}x</span>.</li>
<li><strong>Zašto:</strong> temelj regresije, identifikacije sistema i
optimalnosti pod Gaussom.</li>
<li><strong>Primeri:</strong> linearna/polinomijalna regresija; FIR
identifikacija.</li>
</ul>
<hr />
<h2 data-number="12"
id="nlne-blue-najbolji-linearan-nepomeren-estimator"><span
class="header-section-number">12</span> NLNE / BLUE – Najbolji Linearan
Nepomeren Estimator</h2>
<ul>
<li><strong>Poenta:</strong> Kada ne znamo kompletnu raspodelu, ali
znamo <span class="math inline">E\{x\}</span> i <span
class="math inline">\operatorname{cov}(x)</span>, tražimo
<strong>najbolji linearan nepomeren</strong> estimator.</li>
<li><strong>Skalarni slučaj:</strong> za <span class="math inline">E
x=\theta s</span>, optimum <span class="math inline">a^*=C^{-1}s/(s^T
C^{-1}s)</span>, varijansa <span class="math inline">1/(s^T
C^{-1}s)</span>.</li>
<li><strong>Vektorski slučaj:</strong> <span
class="math inline">\hat\theta=(H^T C^{-1} H)^{-1} H^T C^{-1} x</span>
(isti oblik kao LGM sa obojenim šumom).</li>
<li><strong>Zašto:</strong> robustan okvir kada pdf nije poznat; u LGM
je čak i optimalan (NLNE=NEMV).</li>
<li><strong>Primer:</strong> ponderisano srednje kada su varijanse
merenja različite.</li>
</ul>
<hr />
<h2 data-number="13"
id="emv-mle-estimator-maksimalne-verodostojnosti"><span
class="header-section-number">13</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</h2>
<ul>
<li><strong>Poenta:</strong> Maksimizuje <span
class="math inline">L(\theta)=p(x;\theta)</span> (ili <span
class="math inline">\ell=\ln L</span>).</li>
<li><strong>Osobine:</strong> asimptotski <strong>nepomeren, normalan,
efikasan</strong> (za <span class="math inline">N\to\infty</span>).</li>
<li><strong>Zašto:</strong> univerzalan i često praktičan kada
NEMV/RBLST ne rade; daje iste rezultate kao OLS u Gaussovom
slučaju.</li>
<li><strong>Primer:</strong> Bernoulli <span
class="math inline">p</span>: <span class="math inline">\hat
p=\frac{1}{N}\sum x[n]</span>; konstanta u WGN: <span
class="math inline">\hat A=\bar x</span>.</li>
</ul>
<hr />
<h2 data-number="14"
id="bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="header-section-number">14</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</h2>
<ul>
<li><strong>Poenta:</strong> Parametar <span
class="math inline">\theta</span> je slučajan; koristimo apriorno <span
class="math inline">p(\theta)</span> i dobijamo aposteriorno <span
class="math inline">p(\theta\mid x)\propto
p(x\mid\theta)p(\theta)</span>.</li>
<li><strong>Optimalno za kvadratnu cenu:</strong> <span
class="math inline">\hat\theta=E(\theta\mid x)</span> = EMSKG.</li>
<li><strong>Gauss–Gauss slučaj:</strong> zatvorena forma za <span
class="math inline">\mu_{\theta\mid x}</span> i <span
class="math inline">C_{\theta\mid x}</span>; „data–prior“ fuzija.</li>
<li><strong>Zašto:</strong> ugradnja predznanja; često manja BSKG od
NEMV u proseku.</li>
<li><strong>Primer:</strong> konstanta sa uniformnim ili normalnim
priorom ⇒ shrinkage ka <span class="math inline">\mu_A</span>.</li>
</ul>
<hr />
<h2 data-number="15" id="opšta-bayesovska-estimacija-cena-i-rizik"><span
class="header-section-number">15</span> Opšta Bayesovska estimacija:
cena i rizik</h2>
<ul>
<li><strong>Poenta:</strong> Definišeš <strong>cenu</strong> <span
class="math inline">C(\epsilon)</span> i minimizuješ
<strong>rizik</strong> <span
class="math inline">R=E\,C(\theta-\hat\theta)</span>.</li>
<li><strong>Rezultati:</strong>
<ul>
<li>Kvadratna cena ⇒ <strong>posteriorna sredina</strong>.</li>
<li>Apsolutna cena ⇒ <strong>posteriorna medijana</strong>.</li>
<li>0/1 cena (δ→0) ⇒ <strong>MAP</strong> (posteriorni maksimum).</li>
</ul></li>
<li><strong>Zašto:</strong> omogućava izbor estimatora po zahtevu
aplikacije (robustnost, tolerancija, greške tipa „preko praga“).</li>
<li><strong>Primer:</strong> MAP sa uniformnim ograničenim priorom ⇒
„odsečena“ Gaussova posteriorna.</li>
</ul>
<hr />
<h2 data-number="16"
id="linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="header-section-number">16</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</h2>
<ul>
<li><strong>LEMSKG:</strong> <span
class="math inline">\hat\theta=E\theta + C_{\theta x} C_x^{-1}(x-E
x)</span>. </li>
<li><strong>Geometrija:</strong> projekcija <span
class="math inline">\theta</span> na potprostor koji „nose” <span
class="math inline">x</span>-ovi; <strong>princip
ortogonalnosti</strong>.</li>
<li><strong>Sekvencijalna forma (inovacije):</strong> rekurzivno
ažuriranje preko <span class="math inline">k[n]</span> i kovarijanse
greške <span class="math inline">M[n]</span>.</li>
<li><strong>Zašto:</strong> isti oblik kao Gauss–Bayes; priprema teren
za Kalmanov filter.</li>
<li><strong>Primer:</strong> dodavanje nove merenja kao „projekcije“ na
komponentu inovacije.</li>
</ul>
<hr />
<h2 data-number="17" id="kalmanov-filter-kf"><span
class="header-section-number">17</span> Kalmanov filter (KF)</h2>
<ul>
<li><strong>Model:</strong> Gauss–Markov stanje + BGŠ merenja.</li>
<li><strong>Rekurzije (skalar):</strong>
<ul>
<li>Predikcija: <span class="math inline">\hat s_{n|n-1}=a\,\hat
s_{n-1|n-1}</span>, <span class="math inline">M_{n|n-1}=a^2
M_{n-1|n-1}+\sigma_u^2</span>.</li>
<li>Pojačanje: <span class="math inline">K_n=
M_{n|n-1}/(\sigma_w^2+M_{n|n-1})</span>.</li>
<li>Ažuriranje: <span class="math inline">\hat s_{n|n}=\hat
s_{n|n-1}+K_n\,(x_n-\hat s_{n|n-1})</span>, <span
class="math inline">M_{n|n}=(1-K_n)M_{n|n-1}</span>.</li>
</ul></li>
<li><strong>Zašto:</strong> optimalna sekvencijalna fuzija informacija
(EMSKG=LEMSKG u Gaussovom slučaju); osnov za praćenje, navigaciju,
komunikacije.</li>
<li><strong>Primer:</strong> praćenje sporog signala u šumu; glatkoća vs
odziv zavisi od <span
class="math inline">\sigma_u^2,\sigma_w^2</span>.</li>
</ul>
<hr />
<h2 data-number="18" id="povezanosti-redosled-učenja"><span
class="header-section-number">18</span> Povezanosti (redosled
učenja)</h2>
<ol type="1">
<li><strong>Uvod → SKG/bias–var</strong> (razumevanje metrike)</li>
<li><strong>NEMV → CRLB</strong> (granice, efikasnost)</li>
<li><strong>LGM</strong> (matrični oblik; uslovi; obojeni šum)</li>
<li><strong>NLNE/BLUE</strong> (kada pdf nije poznat → oblik kao u
LGM)</li>
<li><strong>MLE</strong> (opšti metod; asimptotika)</li>
<li><strong>Bayes (EMSKG) → OBE</strong> (posterior, cena/rizik)</li>
<li><strong>LEMSKG</strong> (projekcija, inovacije)</li>
<li><strong>Kalman</strong> (sekvencijalni EMSKG/LEMSKG u GMM)
<a href="#top" class="back-to-top">⇧</a></li>
</ol>
</body>
</html>
