<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Mind Map</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="styles.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Mind Map</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#uvod-i-motivacija" id="toc-uvod-i-motivacija"><span
class="toc-section-number">1</span> Uvod i motivacija</a></li>
<li><a href="#nemv-nepomeren-estimator-minimalne-varijanse"
id="toc-nemv-nepomeren-estimator-minimalne-varijanse"><span
class="toc-section-number">2</span> NEMV – Nepomeren Estimator Minimalne
Varijanse</a></li>
<li><a href="#crlb-cramérrao-donja-granica-fišerova-informacija"
id="toc-crlb-cramérrao-donja-granica-fišerova-informacija"><span
class="toc-section-number">3</span> CRLB – Cramér–Rao Donja Granica
(Fišerova informacija)</a></li>
<li><a href="#lgm-linearni-gaussovski-model-ols"
id="toc-lgm-linearni-gaussovski-model-ols"><span
class="toc-section-number">4</span> LGM – Linearni Gaussovski Model
(OLS)</a></li>
<li><a href="#nlne-blue-najbolji-linearan-nepomeren-estimator"
id="toc-nlne-blue-najbolji-linearan-nepomeren-estimator"><span
class="toc-section-number">5</span> NLNE / BLUE – Najbolji Linearan
Nepomeren Estimator</a></li>
<li><a href="#emv-mle-estimator-maksimalne-verodostojnosti"
id="toc-emv-mle-estimator-maksimalne-verodostojnosti"><span
class="toc-section-number">6</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</a></li>
<li><a href="#bayesovska-filozofija-i-emskg-posteriorna-sredina"
id="toc-bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="toc-section-number">7</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</a></li>
<li><a href="#opšta-bayesovska-estimacija-cena-i-rizik"
id="toc-opšta-bayesovska-estimacija-cena-i-rizik"><span
class="toc-section-number">8</span> Opšta Bayesovska estimacija: cena i
rizik</a></li>
<li><a href="#linearna-bayesovska-estimacija-lemskg-i-geometrija"
id="toc-linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="toc-section-number">9</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</a></li>
<li><a href="#kalmanov-filter-kf" id="toc-kalmanov-filter-kf"><span
class="toc-section-number">10</span> Kalmanov filter (KF)</a></li>
<li><a href="#povezanosti-redosled-učenja"
id="toc-povezanosti-redosled-učenja"><span
class="toc-section-number">11</span> Povezanosti (redosled
učenja)</a></li>
</ul>
</nav>
<h2 data-number="1" id="uvod-i-motivacija"><span
class="header-section-number">1</span> Uvod i motivacija</h2>
<details class="card">
<summary>
<strong>Šta je model u teoriji estimacije?</strong>
</summary>
<div class="card-body">
<p>Model u teoriji estimacije je f.g.v. za opservacije, pri čemu u <span
class="math inline">p</span> figuriše <span
class="math inline">\theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Kada kažemo da je estimator nepomeren?</strong>
</summary>
<div class="card-body">
<p>Kažemo da je estimator nepomeren kada u proseku daje tačnu vrednost
<span class="math inline">E[\hat{\theta}] = \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je pomeraj estimatora?</strong>
</summary>
<div class="card-body">
<p>Pomeraj estimatora ukazuje na sistematsku grešku: <span
class="math inline">b(\theta) = E(\hat{\theta}) - \theta</span>.</p>
</div></details>
<details class="card">
<summary>
<strong>Šta je srednja kvadratna greška estimatora?</strong>
</summary>
<div class="card-body">
<p><span class="math inline">\operatorname{mse}(\hat{\theta})=E\left[
(\hat{\theta} - \theta)^2
\right]=\operatorname{var}(\hat{\theta})+b^2(\theta)</span>. </p>
</div></details>
<hr />
<h2 data-number="2"
id="nemv-nepomeren-estimator-minimalne-varijanse"><span
class="header-section-number">2</span> NEMV – Nepomeren Estimator
Minimalne Varijanse</h2>
<details class="card">
<summary>
<strong>Da li je moguće odrediti EMSKG u frekventističkom
pristupu?</strong>
</summary>
<div class="card-body">
<p>Nije moguće odrediti estimator minimalne srednje kvadratne greške u
frekventističkom pristupu. Ako tražimo <strong>nepomeren</strong>
estimator, želimo onaj sa <strong>najmanjom varijansom</strong>.</p>
</div></details>
<hr />
<ul>
<li><strong>Koraci:</strong>
<ol type="1">
<li>Definiši klasu nepomerenih estimatora (uslov <span
class="math inline">E\hat{\theta}=\theta</span>).</li>
<li>Nađi onaj sa minimalnom varijansom; kada postoji i kada ne
postoji.</li>
</ol></li>
<li><strong>Zašto:</strong> NEMV je „zlatni standard“ u klasi
nepomerenih estimatora; često služi kao referenca (donja granica).</li>
</ul>
<hr />
<h2 data-number="3"
id="crlb-cramérrao-donja-granica-fišerova-informacija"><span
class="header-section-number">3</span> CRLB – Cramér–Rao Donja Granica
(Fišerova informacija)</h2>
<ul>
<li><strong>Poenta:</strong> Donja granica varijanse
<strong>svakog</strong> nepomerenog estimatora: <span
class="math inline">\operatorname{var}(\hat{\theta})\ge
I(\theta)^{-1}</span>.</li>
<li><strong>Formule:</strong>
<ul>
<li>Fišerova informacija: <span
class="math inline">I(\theta)=-E\,\partial^2_\theta\ln
p(x;\theta)=E\left[(\partial_\theta\ln p)^2\right]</span>.</li>
<li>Uslov regularnosti (UR) da bi važilo.</li>
</ul></li>
<li><strong>Zašto:</strong> meri „oštrinu” verodostojnosti – više info ⇒
manja minimalna varijansa; cilj je dostići CRLB (efikasnost).</li>
<li><strong>Primer:</strong> konstanta u WGN ⇒ <span
class="math inline">I=N/\sigma^2</span>, pa <span
class="math inline">\operatorname{var}(\hat A)\ge
\sigma^2/N</span>.</li>
</ul>
<hr />
<h2 data-number="4" id="lgm-linearni-gaussovski-model-ols"><span
class="header-section-number">4</span> LGM – Linearni Gaussovski Model
(OLS)</h2>
<ul>
<li><strong>Model:</strong> <span
class="math inline">x=H\,\theta+w</span>, <span
class="math inline">w\sim\mathcal N(0,\sigma^2 I)</span>.</li>
<li><strong>Efikasni estimator (i NEMV):</strong> <span
class="math inline">\hat{\theta}=(H^T H)^{-1}H^T x</span>. </li>
<li><strong>Varijansa:</strong> <span
class="math inline">C_{\hat{\theta}}=\sigma^2 (H^T H)^{-1}</span>.</li>
<li><strong>Obojeni šum:</strong> prewhitening sa <span
class="math inline">C^{-1}=D^T D</span> ⇒ <span
class="math inline">\hat\theta=(H^T C^{-1} H)^{-1}H^T
C^{-1}x</span>.</li>
<li><strong>Zašto:</strong> temelj regresije, identifikacije sistema i
optimalnosti pod Gaussom.</li>
<li><strong>Primeri:</strong> linearna/polinomijalna regresija; FIR
identifikacija.</li>
</ul>
<hr />
<h2 data-number="5"
id="nlne-blue-najbolji-linearan-nepomeren-estimator"><span
class="header-section-number">5</span> NLNE / BLUE – Najbolji Linearan
Nepomeren Estimator</h2>
<ul>
<li><strong>Poenta:</strong> Kada ne znamo kompletnu raspodelu, ali
znamo <span class="math inline">E\{x\}</span> i <span
class="math inline">\operatorname{cov}(x)</span>, tražimo
<strong>najbolji linearan nepomeren</strong> estimator.</li>
<li><strong>Skalarni slučaj:</strong> za <span class="math inline">E
x=\theta s</span>, optimum <span class="math inline">a^*=C^{-1}s/(s^T
C^{-1}s)</span>, varijansa <span class="math inline">1/(s^T
C^{-1}s)</span>.</li>
<li><strong>Vektorski slučaj:</strong> <span
class="math inline">\hat\theta=(H^T C^{-1} H)^{-1} H^T C^{-1} x</span>
(isti oblik kao LGM sa obojenim šumom).</li>
<li><strong>Zašto:</strong> robustan okvir kada pdf nije poznat; u LGM
je čak i optimalan (NLNE=NEMV).</li>
<li><strong>Primer:</strong> ponderisano srednje kada su varijanse
merenja različite.</li>
</ul>
<hr />
<h2 data-number="6"
id="emv-mle-estimator-maksimalne-verodostojnosti"><span
class="header-section-number">6</span> EMV / MLE – Estimator Maksimalne
Verodostojnosti</h2>
<ul>
<li><strong>Poenta:</strong> Maksimizuje <span
class="math inline">L(\theta)=p(x;\theta)</span> (ili <span
class="math inline">\ell=\ln L</span>).</li>
<li><strong>Osobine:</strong> asimptotski <strong>nepomeren, normalan,
efikasan</strong> (za <span class="math inline">N\to\infty</span>).</li>
<li><strong>Zašto:</strong> univerzalan i često praktičan kada
NEMV/RBLST ne rade; daje iste rezultate kao OLS u Gaussovom
slučaju.</li>
<li><strong>Primer:</strong> Bernoulli <span
class="math inline">p</span>: <span class="math inline">\hat
p=\frac{1}{N}\sum x[n]</span>; konstanta u WGN: <span
class="math inline">\hat A=\bar x</span>.</li>
</ul>
<hr />
<h2 data-number="7"
id="bayesovska-filozofija-i-emskg-posteriorna-sredina"><span
class="header-section-number">7</span> Bayesovska filozofija i EMSKG
(posteriorna sredina)</h2>
<ul>
<li><strong>Poenta:</strong> Parametar <span
class="math inline">\theta</span> je slučajan; koristimo apriorno <span
class="math inline">p(\theta)</span> i dobijamo aposteriorno <span
class="math inline">p(\theta\mid x)\propto
p(x\mid\theta)p(\theta)</span>.</li>
<li><strong>Optimalno za kvadratnu cenu:</strong> <span
class="math inline">\hat\theta=E(\theta\mid x)</span> = EMSKG.</li>
<li><strong>Gauss–Gauss slučaj:</strong> zatvorena forma za <span
class="math inline">\mu_{\theta\mid x}</span> i <span
class="math inline">C_{\theta\mid x}</span>; „data–prior“ fuzija.</li>
<li><strong>Zašto:</strong> ugradnja predznanja; često manja BSKG od
NEMV u proseku.</li>
<li><strong>Primer:</strong> konstanta sa uniformnim ili normalnim
priorom ⇒ shrinkage ka <span class="math inline">\mu_A</span>.</li>
</ul>
<hr />
<h2 data-number="8" id="opšta-bayesovska-estimacija-cena-i-rizik"><span
class="header-section-number">8</span> Opšta Bayesovska estimacija: cena
i rizik</h2>
<ul>
<li><strong>Poenta:</strong> Definišeš <strong>cenu</strong> <span
class="math inline">C(\epsilon)</span> i minimizuješ
<strong>rizik</strong> <span
class="math inline">R=E\,C(\theta-\hat\theta)</span>.</li>
<li><strong>Rezultati:</strong>
<ul>
<li>Kvadratna cena ⇒ <strong>posteriorna sredina</strong>.</li>
<li>Apsolutna cena ⇒ <strong>posteriorna medijana</strong>.</li>
<li>0/1 cena (δ→0) ⇒ <strong>MAP</strong> (posteriorni maksimum).</li>
</ul></li>
<li><strong>Zašto:</strong> omogućava izbor estimatora po zahtevu
aplikacije (robustnost, tolerancija, greške tipa „preko praga“).</li>
<li><strong>Primer:</strong> MAP sa uniformnim ograničenim priorom ⇒
„odsečena“ Gaussova posteriorna.</li>
</ul>
<hr />
<h2 data-number="9"
id="linearna-bayesovska-estimacija-lemskg-i-geometrija"><span
class="header-section-number">9</span> Linearna Bayesovska estimacija
(LEMSKG) i geometrija</h2>
<ul>
<li><strong>LEMSKG:</strong> <span
class="math inline">\hat\theta=E\theta + C_{\theta x} C_x^{-1}(x-E
x)</span>. </li>
<li><strong>Geometrija:</strong> projekcija <span
class="math inline">\theta</span> na potprostor koji „nose” <span
class="math inline">x</span>-ovi; <strong>princip
ortogonalnosti</strong>.</li>
<li><strong>Sekvencijalna forma (inovacije):</strong> rekurzivno
ažuriranje preko <span class="math inline">k[n]</span> i kovarijanse
greške <span class="math inline">M[n]</span>.</li>
<li><strong>Zašto:</strong> isti oblik kao Gauss–Bayes; priprema teren
za Kalmanov filter.</li>
<li><strong>Primer:</strong> dodavanje nove merenja kao „projekcije“ na
komponentu inovacije.</li>
</ul>
<hr />
<h2 data-number="10" id="kalmanov-filter-kf"><span
class="header-section-number">10</span> Kalmanov filter (KF)</h2>
<ul>
<li><strong>Model:</strong> Gauss–Markov stanje + BGŠ merenja.</li>
<li><strong>Rekurzije (skalar):</strong>
<ul>
<li>Predikcija: <span class="math inline">\hat s_{n|n-1}=a\,\hat
s_{n-1|n-1}</span>, <span class="math inline">M_{n|n-1}=a^2
M_{n-1|n-1}+\sigma_u^2</span>.</li>
<li>Pojačanje: <span class="math inline">K_n=
M_{n|n-1}/(\sigma_w^2+M_{n|n-1})</span>.</li>
<li>Ažuriranje: <span class="math inline">\hat s_{n|n}=\hat
s_{n|n-1}+K_n\,(x_n-\hat s_{n|n-1})</span>, <span
class="math inline">M_{n|n}=(1-K_n)M_{n|n-1}</span>.</li>
</ul></li>
<li><strong>Zašto:</strong> optimalna sekvencijalna fuzija informacija
(EMSKG=LEMSKG u Gaussovom slučaju); osnov za praćenje, navigaciju,
komunikacije.</li>
<li><strong>Primer:</strong> praćenje sporog signala u šumu; glatkoća vs
odziv zavisi od <span
class="math inline">\sigma_u^2,\sigma_w^2</span>.</li>
</ul>
<hr />
<h2 data-number="11" id="povezanosti-redosled-učenja"><span
class="header-section-number">11</span> Povezanosti (redosled
učenja)</h2>
<ol type="1">
<li><strong>Uvod → SKG/bias–var</strong> (razumevanje metrike)</li>
<li><strong>NEMV → CRLB</strong> (granice, efikasnost)</li>
<li><strong>LGM</strong> (matrični oblik; uslovi; obojeni šum)</li>
<li><strong>NLNE/BLUE</strong> (kada pdf nije poznat → oblik kao u
LGM)</li>
<li><strong>MLE</strong> (opšti metod; asimptotika)</li>
<li><strong>Bayes (EMSKG) → OBE</strong> (posterior, cena/rizik)</li>
<li><strong>LEMSKG</strong> (projekcija, inovacije)</li>
<li><strong>Kalman</strong> (sekvencijalni EMSKG/LEMSKG u GMM)
<a href="#top" class="back-to-top">⇧</a></li>
</ol>
<!-- cache-bust 20250813111412 --></body>
</html>
